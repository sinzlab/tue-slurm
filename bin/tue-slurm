#!/usr/bin/env python3

import argparse
import os
import stat
import subprocess
from pathlib import Path
from time import sleep


class SlurmJob:
    def __init__(
        self,
        name,
        time,
        gpu,
        num_gpus,
        num_cpus,
        memory,
        email,
        on_local,
        run_script,
        singularity_img,
        clone_src_to_work,
        unk_args,
        index=0,
    ):
        host_name = os.environ.get("HOSTNAME", "")
        self.on_tue_cluster = "bg-slurmb" in host_name

        self.name = f"{name}-{index}"
        self.email = email
        self.time = time

        days, hours, minutes = list(
            map(int, [time.split("-")[0]] + time.split("-")[1].split(":"))
        )
        if self.on_tue_cluster:
            print("ON TUE CLUSTER")
            if "2080" in gpu:
                self.gpu = "gpu-2080ti-dev" if hours < 12 else "gpu-2080ti"
            else:
                self.gpu = "gpu-v100"
        else:
            self.gpu = gpu  # "gtx1080", "v100", "gtx2080" "rtx5000"
            self.partition = "gpu"
            self.scratch = "scratch2" if gpu in ("gtx1080", "gtx980") else "scratch"
        self.num_gpus = num_gpus
        self.num_cpus = num_cpus
        self.memory = memory
        self.on_slurm = not on_local
        self.run_script = run_script
        self.run_args = " ".join(unk_args)
        self.singularity_img = singularity_img
        self.clone_src_to_work = clone_src_to_work

        if self.on_tue_cluster:
            self.src_dir = "$HOME/projects"
            self.work_dir = "$SCRATCH/work"
        elif self.on_slurm:
            self.src_dir = "$HOME/src"
            self.work_dir = "$SCRATCH/scratch/users/$USER/$SLURM_JOB_ID"
        else:
            self.src_dir = "$HOME/projects"
            self.work_dir = "$HOME/projects/work"

    @property
    def resource_config_string(self):
        if not Path("logs").exists():
            os.mkdir("logs")
        config_string = f"""
#SBATCH --job-name={self.name}                   # Name of the job
#SBATCH --ntasks=1                          # Number of tasks
#SBATCH --cpus-per-task={self.num_cpus}                   # Number of CPU cores per task
#SBATCH --nodes=1                           # Ensure that all cores are on one machine
#SBATCH --time={self.time}                       # Runtime in D-HH:MM
#SBATCH --mem-per-cpu={self.memory}              # Memory pool for all cores (see also --mem-per-cpu)
#SBATCH --output=logs/{self.name}.%j.out              # File to which STDOUT will be written
#SBATCH --error=logs/{self.name}.%j.err               # File to which STDERR will be written
#SBATCH --mail-type=ALL                     # Type of email notification- BEGIN,END,FAIL,ALL
#SBATCH --mail-user={self.email}                 # Email to which notifications will be sent
"""
        if self.on_tue_cluster:
            config_string += f"""
#SBATCH --partition={self.gpu}                   # Partition to submit to
#SBATCH --gres=gpu:{self.num_gpus}
            """
        else:
            config_string += f"""
#SBATCH --constraint="{self.scratch}"                # Mount scratch
#SBATCH -p {self.partition}                   # Partition to submit to
#SBATCH --gpus={self.gpu}:{self.num_gpus}               # Number of requested GPUs
            """
        return config_string

    @property
    def singularity_run_command(self):
        run_cmd = f"""
            export SRCDIR={self.src_dir}
            export WORKDIR={self.work_dir}
            mkdir -p $WORKDIR
        """
        if self.clone_src_to_work:
            run_cmd += f"""
            mkdir -p $WORKDIR/src
            start_dir=$(pwd)
            cd $SRCDIR
            for d in */ ; do
                cd $d
                if [ -d .git ]; then
                    git clone . $WORKDIR/src/$d
                fi;
                cd ..
            done
            export SRCDIR=$WORKDIR/src
            cd $start_dir
            """

        if self.on_slurm:
            if not self.on_tue_cluster:
                run_cmd += f"""
                module purge
                module load singularity
                module load cuda
                """

            run_cmd += f"""
                mkdir -p $HOME/.local
                mkdir -p $HOME/.cache
                scontrol show job $SLURM_JOB_ID  # print some info

                singularity exec \
                --nv \
                --env-file .env \
                --no-home  \
                --bind $SRCDIR:/src,$WORKDIR:/work,$HOME/.local/:$HOME/.local/,$HOME/.cache/:$HOME/.cache/  \
                {self.singularity_img} \
                {self.run_script} {self.run_args}

                    """
        else:
            run_cmd += f"""
                singularity instance start \
                         --nv \
                         --env-file .env \
                         --env "CUDA_VISIBLE_DEVICES={self.gpu}" \
                         --no-home  \
                         --bind $HOME/.activeloop:$HOME/.activeloop,$HOME/.config:$HOME/.config,$HOME/.netrc:$HOME/.netrc,$HOME/.vscode-server:$HOME/.vscode-server,$SRCDIR:/src,$WORKDIR:/work,$HOME/.local/:$HOME/.local/,$HOME/.cache/:$HOME/.cache/,/tmp/djcache:/cache,/var/sinz-shared:/var/sinz-shared \
                         {self.singularity_img} {self.name} \
                         {self.run_script} {self.run_args}
            """
            # run_cmd += f"""
            #     singularity exec --env "CUDA_VISIBLE_DEVICES={self.gpu}" \
            #              --nv \
            #              --env-file .env \
            #              --no-home  \
            #              --bind $SRCDIR:/src,$WORKDIR:/work,$HOME/.local/:$HOME/.local/,$HOME/.cache/:$HOME/.cache/,/tmp/djcache:/cache,/var/sinz-shared:/var/sinz-shared \
            #              {self.singularity_img}  \
            #              {self.run_script} {self.run_args}
            # """
        return run_cmd

    def run(self):
        if self.on_slurm:
            slurm_job_bash_file = f"./{self.name}.sh"
            slurm_job_bash_file_content = (
                "#!/bin/bash \n \n"
                + self.resource_config_string
                + "\n"
                + self.singularity_run_command
            )
            with open(slurm_job_bash_file, "w") as f:
                f.write(slurm_job_bash_file_content)

            os.chmod(slurm_job_bash_file, stat.S_IRWXU)

            try:
                output = subprocess.check_output(
                    "sbatch " + slurm_job_bash_file, shell=True
                )
                sleep(5)
                job_id = int(output[20:].strip())
                node = subprocess.check_output(
                    f"scontrol show job {job_id}| grep ' NodeList'", shell=True
                ).strip()
                node = str(node).split("=")[1][:-1]
                print(f"Successfully submitted job with ID {job_id} to node {node}.")
                print(self.resource_config_string)
                print(self.singularity_run_command)
            finally:
                # remove the bash file
                os.remove(slurm_job_bash_file)
        else:
            print(self.singularity_run_command)
            print(subprocess.check_output(self.singularity_run_command, shell=True))


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Running jobs on SLURM cluster")
    parser.add_argument(
        "--run",
        dest="run_script",
        action="store",
        default="run.py",
        type=str,
        help="",
    )
    parser.add_argument(
        "--njobs",
        dest="num_jobs",
        action="store",
        default=1,
        type=int,
        help="",
    )
    parser.add_argument(
        "--name",
        dest="name",
        action="store",
        default="noname",
        type=str,
        help="",
    )
    parser.add_argument(
        "--time",
        dest="time",
        action="store",
        default="0-01:00",
        type=str,
        help="time to complete each job. Specify in the following format: D-HH:MM",
    )
    parser.add_argument(
        "--gpu",
        dest="gpu",
        action="store",
        default="gpu-2080ti",
        type=str,
        help="",
    )
    parser.add_argument(
        "--ncpus",
        dest="num_cpus",
        action="store",
        default=2,
        type=int,
        help="",
    )
    parser.add_argument(
        "--ngpus",
        dest="num_gpus",
        action="store",
        default=1,
        type=int,
        help="",
    )
    parser.add_argument(
        "--memory",
        dest="memory",
        action="store",
        default=3000,
        type=int,
        help="",
    )
    parser.add_argument(
        "--email",
        dest="email",
        action="store",
        default=os.getenv("EMAIL"),
        type=str,
        help="",
    )
    parser.add_argument(
        "--local",
        dest="local",
        default=False,
        action="store_true",
        help="Specify whether this is a job on SLURM or a local machine.",
    )
    parser.add_argument(
        "--img",
        dest="singularity_img",
        action="store",
        default="shub://sinzlab/pytorch-singularity:v3.8-torch1.7.0-dj0.12.7",
        type=str,
        help="Singularity image to use",
    )
    parser.add_argument(
        "--clone_src_to_work",
        dest="clone_src_to_work",
        action="store_true",
        default=False,
        help="Whether the source directory should be mounted directly to /src/ in the container "
        "or clone it to the working directory and mount from there.",
    )

    args, unk_args = parser.parse_known_args()

    for job_index in range(args.num_jobs):
        job = SlurmJob(
            args.name,
            args.time,
            args.gpu,
            args.num_gpus,
            args.num_cpus,
            args.memory,
            args.email,
            args.local,
            args.run_script,
            args.singularity_img,
            args.clone_src_to_work,
            unk_args,
            index=job_index,
        )
        job.run()
